{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Homework**\n",
    "\n",
    "* **1bp** Analyze the *Harry Potter* eye/smile detector and it's failcases. Come with possible causes for this issue, based on the way variation is encoded and used in searching for matches. Propose a solution for the identified *eye detector* failcase.\n",
    "    * The Harry Potter eye detector fails due to the fact that Harry is wearing glasses. Glasses are  partially\n",
    "transparent, this means that some light is reflected (the refraction could also be a negative factor, for high diopter lenses).\n",
    "Moreover, the margin of the glasses have pixels with a different intensity, changing the\n",
    "variance around the eyes, which might trick the algorithm.\n",
    "    * For smile, it is similar, the classifier learns to recognize features similar to two semicircles with some variation\n",
    "of the color in the center. More training instances could be used such that the classifiers also learns the correct range of\n",
    "colors.\n",
    "    * A solution would be to apply histogram equalization before the haar-cascade.\n",
    "* **1bp** To overcome the difficulty of MeanShift when the object orientation was changing dramatically, the CamShift algorithm was proposed. Experiment with *OpenCV* CamShift on a video sequence where MeanShift performs poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "video_capture = cv.VideoCapture(\"sample_video.avi\")\n",
    "out_dir = 'meanshift_demo'\n",
    "\n",
    "\n",
    "ret_cap, frame = video_capture.read()\n",
    "print(frame.shape)\n",
    "\n",
    "# initialize window for face\n",
    "x, y, w, h = (100, 45, 25, 30)\n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "# set the region of interest (ROI)\n",
    "roi = frame[y: y+h, x: x+w]\n",
    "roi_hsv = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
    "mask = cv.inRange(roi_hsv, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "\n",
    "roi_hist = cv.calcHist([roi_hsv],[0],mask,[180],[0,180])\n",
    "cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
    "\n",
    "\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by atleast 1 pt\n",
    "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "\n",
    "fnums = []\n",
    "x_s = []\n",
    "y_s = []\n",
    "ret = True\n",
    "fnum = 0\n",
    "\n",
    "while True:\n",
    "  ret_cap, frame = video_capture.read()\n",
    "  fnum += 1\n",
    "\n",
    "  if not ret_cap:\n",
    "    break\n",
    "\n",
    "  hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "  dst = cv.calcBackProject([hsv], [0], roi_hist, [0,180], 1) # find the best batching displacement\n",
    "  ret, track_window = cv.CamShift(dst, track_window, term_crit) # use meanshift based on the displacement\n",
    "  x,y,w,h = track_window\n",
    "\n",
    "  plot_img = frame.copy()\n",
    "\n",
    "  x_s.append(x + w // 2)\n",
    "  y_s.append(y + h // 2)\n",
    "  cv.rectangle(plot_img, (x, y), (x+w, y+h), (255, 255, 255), 3)\n",
    "  fnums.append(fnum)\n",
    "\n",
    "  cv.imwrite(\"{}/1-{}.png\".format(out_dir, str(fnum - 1).zfill(3)), plot_img)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* **1bp** Given a stereo-vision system and an obstacle detection problem, describe a pipeline used to decide if your moving object fits through the space between two identified obstacles. (No implementation needed. Describe how would you approach the given problem, based on the topics discussed in the exercise sessions).\n",
    "    * The two identified obstacles should be tracked. The distance between their margin is traced at each frame (frame 0, frame 1, ...)\n",
    " and based on the speed of the moving object and the displacement of the pixels from 1 frame to another we are able to calculate\n",
    "the distance between the object and each obstacle (using Triangle Similarity) and the relative distance between obstacles."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}